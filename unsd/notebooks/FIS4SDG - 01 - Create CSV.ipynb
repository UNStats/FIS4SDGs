{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing script\n",
    "This script pulls SDG data from API and transforms it into csv files.\n",
    "The steps are:\n",
    "- Pull data from [API](https://unstats.un.org/SDGAPI/swagger/) \n",
    "- Join with geography\n",
    "- save as \"long\" table\n",
    "- pivot into \"wide\" format and split regional and country data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import urllib3  # allows to access a URL with python\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "\n",
    "# https://volderette.de/jupyter-notebook-tip-multiple-outputs/\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release = '2019.Q1.G.02' # Make sure to have the correct release here\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(dir_path)\n",
    "\n",
    "wd_dir = r'../'\n",
    "print('data inputs dir: ' + wd_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert string to camelCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camelCase(st):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/8347048/camelcase-every-string-any-standard-library\n",
    "    \n",
    "    \"\"\"\n",
    "    output = ''.join(x for x in st.title() if x.isalnum())\n",
    "    return output[0].lower() + output[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disable insecure request warnings when using `urllib3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array to catch errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_log = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of countries to be plotted on a map (with XY coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countryListXY(file):\n",
    "    \n",
    "    countryListXY = []\n",
    "    \n",
    "    with open(file, newline = '', encoding='latin-1') as countryList:                                                                                          \n",
    "        countryList = csv.DictReader(countryList, delimiter='\\t')\n",
    "        for row in countryList:\n",
    "            countryListXY.append(dict(row))\n",
    "            \n",
    "    countryListXY = pd.DataFrame(countryListXY).astype({'geoAreaCode':'str'})\n",
    "    \n",
    "    return(countryListXY)\n",
    "\n",
    "    #print(countryListXY[1])\n",
    "    #for c in countryListXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryListXY(wd_dir + 'CountryListXY.txt').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the endpoint of the SDG API that provides the list of hierarchical groupings of geographic Areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geoAreaTree():\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', \"https://unstats.un.org/SDGAPI/v1/sdg/GeoArea/Tree\")\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    return responseData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The geoAreaTree object has various \"trees\" in it.  We usually use the \"World\" tree; however, some economic and geographic groupings are only in other trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(geoAreaTree()))\n",
    "for t in geoAreaTree():\n",
    "    print('root='+t['geoAreaName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traverse a hierarchical tree of geographic areas and convert it to a parent-child hierarchy table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(tree):\n",
    "    \n",
    "    global hierarchy\n",
    "    \n",
    "    hierarchy = []\n",
    "    traverse.level = 1\n",
    "    traverse(tree)\n",
    "    \n",
    "    return pd.DataFrame(hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(tree, parentCode=None, parentName=None):\n",
    "    \n",
    "    # print(' ' * traverse.level + 'Level: ' + str(traverse.level) + ', ' + tree['type'] + ', ' + str(tree['geoAreaCode']) + '-' + tree['geoAreaName'] )\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    d['level'] = traverse.level\n",
    "    d['type'] = tree['type']\n",
    "    d['parentCode'] = parentCode\n",
    "    d['parentName'] = parentName\n",
    "    d['geoAreaCode'] = str(tree['geoAreaCode'])\n",
    "    d['geoAreaName'] = tree['geoAreaName']\n",
    "    \n",
    "    hierarchy.append(d)\n",
    "        \n",
    "    if tree['children']:\n",
    "        for child in tree['children']:\n",
    "            traverse.level += 1\n",
    "            traverse(child, str(tree['geoAreaCode']), tree['geoAreaName'])\n",
    "            traverse.level -= 1\n",
    "    \n",
    "    return pd.DataFrame(hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `geoAreas` holds the flattened list of geographic areas under 'World':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoAreas = flatten(geoAreaTree()[0])\n",
    "geoAreas.head()\n",
    "print('...')\n",
    "geoAreas.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temporary Fix for missing regions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if('910' not in geoAreas['geoAreaCode']):\n",
    "    d_910 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '910',\n",
    "              'geoAreaName' : 'High income economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_910.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('911' not in geoAreas['geoAreaCode']):\n",
    "    d_911 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '911',\n",
    "              'geoAreaName' : 'Low income economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_911.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "    \n",
    "if('912' not in geoAreas['geoAreaCode']):\n",
    "    d_912 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '912',\n",
    "              'geoAreaName' : 'Lower middle economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_912.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('913' not in geoAreas['geoAreaCode']):\n",
    "    d_913 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '913',\n",
    "              'geoAreaName' : 'Low and middle income economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_913.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('914' not in geoAreas['geoAreaCode']):\n",
    "    d_914 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '914',\n",
    "              'geoAreaName' : 'Upper middle economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_914.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('135' not in geoAreas['geoAreaCode']):\n",
    "    d_135 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '135',\n",
    "              'geoAreaName' : 'Caucasus and Central Asia'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_135.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('127' not in geoAreas['geoAreaCode']):\n",
    "    d_127 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '127',\n",
    "              'geoAreaName' : 'Southern Asia (excluding India)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_127.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('199' not in geoAreas['geoAreaCode']):\n",
    "    d_199 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '199',\n",
    "              'geoAreaName' : 'Least Developed Countries (LDC)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_199.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('485' not in geoAreas['geoAreaCode']):\n",
    "    d_485 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '485',\n",
    "              'geoAreaName' : 'Western Asia (exc. Armenia, Azerbaijan, Cyprus, Israel and Georgia)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_485.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('514' not in geoAreas['geoAreaCode']):\n",
    "    d_514 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '514',\n",
    "              'geoAreaName' : 'Developed Regions'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_514.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('515' not in geoAreas['geoAreaCode']):\n",
    "    d_515 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '515',\n",
    "              'geoAreaName' : 'Developing Regions'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_515.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('518' not in geoAreas['geoAreaCode']):\n",
    "    d_518 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '518',\n",
    "              'geoAreaName' : 'Eastern Asia (excluding Japan)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_518.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('738' not in geoAreas['geoAreaCode']):\n",
    "    d_738 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '738',\n",
    "              'geoAreaName' : 'Sub-Saharan Africa (inc. Sudan)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_738.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "                 \n",
    "if('746' not in geoAreas['geoAreaCode']):\n",
    "    d_746 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '746',\n",
    "              'geoAreaName' : 'Northern Africa (exc. Sudan)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_746.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "#==================================\n",
    "\n",
    "geoAreas = geoAreas.reset_index(drop=True)\n",
    "\n",
    "geoAreas.tail(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge coordinates and list of geographic areas in SDG database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoAreas.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geoareasXY(geoareas,coordinates_file):\n",
    "    \n",
    "    xy = countryListXY(coordinates_file)\n",
    "    \n",
    "    x = pd.merge(geoareas,xy.loc[:, xy.columns != 'geoAreaName'],\n",
    "         how='outer',\n",
    "         on=['geoAreaCode'])\n",
    "    x['order'] = x['geoAreaCode']\n",
    "    x['order'] = x['order'].astype(float)\n",
    "    x = x.sort_values('order')\n",
    "    del x['order']\n",
    "    \n",
    "    x = x.reset_index(drop=True)\n",
    "    \n",
    "    return(x)\n",
    "\n",
    "# x.to_excel('test.xlsx', engine ='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoareasXY(geoAreas, wd_dir + 'CountryListXY.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of goals, targets, indicators and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_list(release):\n",
    "    \n",
    "    series_list = []\n",
    "\n",
    "    # Call the endpoint of the SDG API that provides the list of goals with all their children:\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', \"https://unstats.un.org/SDGAPI/v1/sdg/Goal/List?includechildren=true\")\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    # Define the list of 'keys' to be extracted into a flat dictionary from the response:\n",
    "    keys = [\"goalCode\", \n",
    "            \"goalDesc\",\n",
    "            \"targetCode\",\n",
    "            \"targetDesc\",\n",
    "            \"indicatorCode\",\n",
    "            \"indicatorDesc\",\n",
    "            \"indicatorTier\",\n",
    "            \"seriesCode\",\n",
    "            \"seriesDesc\",\n",
    "            \"seriesRelease\"\n",
    "           ]    \n",
    "    \n",
    "    # Iterate over goals, targets, indicators, and series for the specified release:\n",
    "    for g in responseData:\n",
    "        for t in g['targets']:\n",
    "            for i in t['indicators']:\n",
    "                for s in i['series']:\n",
    "                    if s['release'] == release:\n",
    "                        values = [g['code'], g['title'],\n",
    "                                  t['code'], t['description'], \n",
    "                                  i['code'], i['description'], i['tier'], \n",
    "                                  s['code'], s['description'], s['release']]\n",
    "\n",
    "                        keys_and_values = zip(keys, values)\n",
    "                        serie_dic = {}\n",
    "                        for key, value in keys_and_values:\n",
    "                            serie_dic[key] = value\n",
    "                        series_list.append(serie_dic)\n",
    "                        \n",
    "    series_list = pd.DataFrame(series_list)\n",
    "    \n",
    "    return series_list[['goalCode', 'goalDesc',\n",
    "                       'targetCode', 'targetDesc',\n",
    "                       'indicatorCode', 'indicatorDesc','indicatorTier', \n",
    "                       'seriesCode', 'seriesDesc', 'seriesRelease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list(release).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Join geographic area catalogue (with coordinates) and series catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_geo_series(geoAreas, countryXY, seriesCode, release):\n",
    "    df1 = geoareasXY(geoAreas, countryXY)\n",
    "    df2 = series_list(release)\n",
    "    \n",
    "    df2 = df2.loc[df2['seriesCode']==seriesCode]\n",
    "\n",
    "    df1['key'] = 1\n",
    "    df2['key'] = 1\n",
    "\n",
    "    x = pd.merge(df1, df2,on='key')\n",
    "    x.drop(['key'], axis=1, inplace=True)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cross_geo_series(geoAreas, wd_dir + 'CountryListXY.txt','SE_ACC_COMP','2019.Q1.G.02')\n",
    "x.head()\n",
    "print('...')\n",
    "x.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data for each series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify how many pages need to be requested to get all the data for a specific series from the SDG API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_request_details(seriesCode,release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\"\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    pageSize = 500\n",
    "    nPages = math.floor(responseData['totalElements'] / pageSize) + 1\n",
    "    totalElements = responseData['totalElements']\n",
    "    \n",
    "    return {'series' : seriesCode,\n",
    "            'totalElements' : totalElements,\n",
    "            'nPages' : nPages, \n",
    "            'pageSize' : pageSize\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_request_details('SE_ACC_COMP', '2019.Q1.G.02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the code lists of the attributes and dimensions of a series\n",
    "Describe each attribute or dimension as a simple dictionary made of a set of `code`-`description` pairs.  For the code, use the SDMX code, and not the internal codeof the database.  Keep all labels in camelCase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_code_lists(seriesCode, release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\"\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    series_attributes = responseData['attributes']\n",
    "    series_dimensions = responseData['dimensions']\n",
    "    \n",
    "    new_dict = {}\n",
    "    \n",
    "    new_dict['seriesCode'] = seriesCode\n",
    "    \n",
    "    for a in series_attributes:\n",
    "        codelist_dict = {}\n",
    "        for c in a['codes']:\n",
    "            codelist_dict[c['code']] = c['description']\n",
    "        new_dict[camelCase(a['id'])] = codelist_dict\n",
    "    \n",
    "    for d in series_dimensions:\n",
    "        codelist_dict = {}\n",
    "        for c in d['codes']:\n",
    "            codelist_dict[c['code']] = c['description']\n",
    "        new_dict[camelCase(d['id'])] = codelist_dict\n",
    "        \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_code_lists('SE_ACC_COMP', '2019.Q1.G.02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplify further by presenting all the codes and their descriptions in a single table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_code_lists2(seriesCode, release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\" \n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    series_attributes = responseData['attributes']\n",
    "    series_dimensions = responseData['dimensions']\n",
    "    \n",
    "    code_list = []\n",
    "    \n",
    "    for a in series_attributes:\n",
    "       \n",
    "        for c in a['codes']:\n",
    "            new_dict = {}\n",
    "            new_dict['series'] = seriesCode\n",
    "            new_dict['role'] = 'attribute'\n",
    "            new_dict['concept'] = camelCase(a['id'])\n",
    "            new_dict['code'] = c['sdmx']\n",
    "            new_dict['description'] = c['description']\n",
    "            code_list.append(new_dict)\n",
    "        \n",
    "    for d in series_dimensions:\n",
    "        for c in d['codes']:\n",
    "            new_dict = {}\n",
    "            new_dict['series'] = seriesCode\n",
    "            new_dict['role'] = 'dimension'\n",
    "            new_dict['concept'] = camelCase(d['id'])\n",
    "            new_dict['code'] = c['sdmx']\n",
    "            new_dict['description'] = c['description']\n",
    "            code_list.append(new_dict)\n",
    "        \n",
    "    return pd.DataFrame(code_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_code_lists2('SE_ACC_COMP', '2019.Q1.G.02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build query string to collect data for a specific series from the global SDG API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_query(seriesCode, release, page, pageSize):\n",
    "    queryString =  r'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + '&page=' + str(page) + '&pageSize=' + str(pageSize)\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', queryString)\n",
    "    responseData =  json.loads(response.data.decode('UTF-8'))\n",
    "    return(responseData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data for a specific series from the API\n",
    "*(!) Notice that a data point may appear more than once if it belongs to a \"multi-purpose indicator\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_data(seriesCode, release):\n",
    "    x = series_request_details(seriesCode,release)\n",
    "    series_data = []\n",
    "    if x['totalElements'] > 0:\n",
    "        for p in range(x['nPages']):\n",
    "            print(\"---Series \" + seriesCode + \": Processing page \" + str(p+1) + \" of \" + str(x['nPages']))\n",
    "            responseData =  series_query(seriesCode, release, p+1, x['pageSize'])\n",
    "            if len(responseData['data'])>0:\n",
    "                series_data = series_data + responseData['data'] \n",
    "    return series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_data('SE_ACC_COMP','2019.Q1.G.02')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten the dictionary, extracting individual attributes and dimensions as key-value pairs in their own right.\n",
    "Also convert the years (`timePeriod`) variable to `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_series_data(seriesCode,release):\n",
    "    new_x = []\n",
    "    for d in series_data(seriesCode,release):\n",
    "        new_d = {}\n",
    "        for key, value in d.items():\n",
    "            if type(value) is list:\n",
    "                new_d[key] = ', '.join(value)\n",
    "            elif type(value) is dict:\n",
    "                for k, v in value.items():\n",
    "                    new_d[camelCase(k+' Code')] = v\n",
    "            elif key == 'time_detail':\n",
    "                new_d[camelCase(key)] = value\n",
    "            elif key == 'timePeriodStart':\n",
    "                new_d['timePeriod'] = int(value)\n",
    "            elif key == 'series':\n",
    "                new_d['seriesCode'] = value\n",
    "            elif key == 'seriesDescription':\n",
    "                new_d['seriesDesc'] = value\n",
    "            elif key == 'geoAreaCode':\n",
    "                new_d['geoAreaCode'] = str(value)\n",
    "            else:\n",
    "                new_d[key] = value\n",
    "        new_x.append(new_d)\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_series_data('SE_ACC_COMP','2019.Q1.G.02')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert flattened dictionary of data series to pandas data frame, remove goal/target/indicator columns, and remove duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_unique_series_data(seriesCode,release):\n",
    "    d = flat_series_data(seriesCode,release)\n",
    "    x = pd.DataFrame(d, \n",
    "                     columns=d[0].keys())\n",
    "    x.drop(['goal','target','indicator', 'seriesCount'], axis=1, inplace=True)\n",
    "    x.drop_duplicates(inplace=True)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe_unique_series_data('SE_ACC_COMP','2019.Q1.G.02')\n",
    "x.to_excel('test2.xlsx', engine ='xlsxwriter')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add descriptions to coded dimension and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotated_data(seriesCode, release):\n",
    "    code_lists = series_code_lists(seriesCode, release)\n",
    "    #print(code_lists)\n",
    "    \n",
    "    s = dataframe_unique_series_data(seriesCode,release)\n",
    "    #print(s)\n",
    "    \n",
    "    concepts = code_lists.keys()\n",
    "    #print(concepts)\n",
    "    \n",
    "    for c in concepts:\n",
    "        if c != 'seriesCode':\n",
    "            #print(c)\n",
    "            d = code_lists[c]\n",
    "            #print(d)\n",
    "            \n",
    "            x = pd.DataFrame(list(d.items()))\n",
    "            x.columns = [c+'Code', c+'Desc']\n",
    "            \n",
    "            s = pd.merge(s, x,on=c+'Code')\n",
    "            s = s.reset_index(drop=True)\n",
    "            \n",
    "    return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = annotated_data('SL_ISV_IFRM','2019.Q1.G.02')\n",
    "print(x.columns)\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce 'long' files for each indicator/series combination\n",
    "(Notice that multi-purpose indicators need to be split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'SL_ISV_IFRM'\n",
    "release = '2019.Q1.G.02'\n",
    "\n",
    "print(s)\n",
    "print(release)\n",
    "\n",
    "x = annotated_data(s,release)\n",
    "print(x.columns)\n",
    "print(x.shape)\n",
    "x.tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(series_list(release).seriesCode))[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'SG_HAZ_CMRBASEL'\n",
    "\n",
    "data = annotated_data(s,release)\n",
    "data = data.drop(['seriesDesc' , 'geoAreaName'] , axis='columns')\n",
    "\n",
    "time_values = data[['timePeriod']].drop_duplicates()\n",
    "\n",
    "time_values['key'] = 0\n",
    "    \n",
    "data_key =  data.drop(['geoAreaCode', 'timePeriod', 'value', 'valueType', 'timeDetail', 'source', 'footnotes', \n",
    "                       'natureCode', 'unitsCode', 'reportingTypeCode','natureDesc', 'unitsDesc', 'reportingTypeDesc'] , axis='columns').drop_duplicates()\n",
    "\n",
    "data_dimensions = list(data_key.columns) + ['geoAreaCode','timePeriod']\n",
    "\n",
    "\n",
    "data_dimensions \n",
    "\n",
    "data_key['key'] = 0\n",
    "\n",
    "geo = geoareasXY(geoAreas, wd_dir + 'CountryListXY.txt')\n",
    "geo['key'] = 0\n",
    "\n",
    "xx = pd.merge(pd.merge(time_values, geo, on='key', how = 'left'),\n",
    "              data_key, on='key', how ='left')\n",
    "\n",
    "xx.drop('key',1, inplace=True)\n",
    "\n",
    "xx = pd.merge(xx, data, how='left', on=data_dimensions)\n",
    "\n",
    "xx.columns\n",
    "\n",
    "\n",
    "indicators = series_list(release)\n",
    "indicators = indicators.loc[indicators['seriesCode']==s]\n",
    "\n",
    "for i in indicators['indicatorCode']:\n",
    "    print(i)\n",
    "    indicators.columns\n",
    "    xx.columns\n",
    "    y = pd.merge(indicators, xx, on='seriesCode')\n",
    "    y.head() \n",
    "    print(y.columns)\n",
    "    print(y.shape)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for s in list(set(series_list(release).seriesCode)):\n",
    "for s in list(set(series_list(release).seriesCode))[0:100]:\n",
    "\n",
    "\n",
    "    data = annotated_data(s,release)\n",
    "    data = data.drop(['seriesDesc' , 'geoAreaName'] , axis='columns')\n",
    "\n",
    "    time_values = data[['timePeriod']].drop_duplicates()\n",
    "\n",
    "    time_values['key'] = 0\n",
    "\n",
    "    data_key =  data.drop(['geoAreaCode', 'timePeriod', 'value', 'valueType', 'timeDetail', 'source', 'footnotes', \n",
    "                           'natureCode', 'unitsCode', 'reportingTypeCode','natureDesc', 'unitsDesc', 'reportingTypeDesc'] , axis='columns').drop_duplicates()\n",
    "\n",
    "    data_dimensions = list(data_key.columns) + ['geoAreaCode','timePeriod']\n",
    "\n",
    "\n",
    "    data_dimensions \n",
    "\n",
    "    data_key['key'] = 0\n",
    "\n",
    "    geo = geoareasXY(geoAreas, wd_dir + 'CountryListXY.txt')\n",
    "    geo['key'] = 0\n",
    "\n",
    "    xx = pd.merge(pd.merge(time_values, geo, on='key', how = 'left'),\n",
    "                  data_key, on='key', how ='left')\n",
    "\n",
    "    xx.drop('key',1, inplace=True)\n",
    "\n",
    "    xx = pd.merge(xx, data, how='left', on=data_dimensions)\n",
    "\n",
    "    xx.columns\n",
    "\n",
    "\n",
    "    indicators = series_list(release)\n",
    "    indicators = indicators.loc[indicators['seriesCode']==s]\n",
    "\n",
    "    for i in indicators['indicatorCode']:\n",
    "        y = pd.merge(indicators, xx, on='seriesCode')\n",
    "        #y.head() \n",
    "        #print(y.columns)\n",
    "        #print(y.shape)\n",
    "        y.to_excel(wd_dir + 'Data_' + i + '_' + s + '.xlsx', engine ='xlsxwriter', index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'SL_ISV_IFRM'\n",
    "series_data(s, release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list('2019.Q1.G.02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
